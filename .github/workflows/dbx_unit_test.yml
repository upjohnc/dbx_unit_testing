name: Pyspark Unit Tests

on:
  push:
    branches:
      # pointing out to change the spelling of the branch for your own repo
      # misspelled here to keep it from running each time
      - "master-" 


permissions:
  contents: read

jobs:
  dbx-deploy:
    name: "Deploy bundle"
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - uses: databricks/setup-cli@v0.218.1

      # Deploy the bundle to the "qa" target as defined
      # in the bundle's settings file.
      - run: databricks bundle deploy
        working-directory: .
        env:
          DATABRICKS_TOKEN: ${{ secrets.SP_TOKEN }}
          DATABRICKS_BUNDLE_ENV: dev

  pipeline_unit_test:
    name: "Run pipeline unit test"
    runs-on: ubuntu-latest

    # Run the "deploy" job first.
    needs:
      - dbx-deploy

    steps:
      # Check out this repo, so that this workflow can access it.
      - uses: actions/checkout@v4

      # Use the downloaded Databricks CLI.
      - uses: databricks/setup-cli@v0.218.1

      # Run the Databricks workflow named "my-job" as defined in the
      # bundle that was just deployed.
      - run: databricks bundle run unit_test --full-refresh-all
        working-directory: .
        env:
          DATABRICKS_TOKEN: ${{ secrets.SP_TOKEN }}
          DATABRICKS_BUNDLE_ENV: dev

  dbx_bundle_clean_up:
    name: "Remove bundle resources after successful run of unit tests"
    runs-on: ubuntu-latest

    # Run the "deploy" job first.
    needs:
      - pipeline_unit_test

    steps:
      # Check out this repo, so that this workflow can access it.
      - uses: actions/checkout@v4

      # Use the downloaded Databricks CLI.
      - uses: databricks/setup-cli@v0.218.1

      # Run the Databricks workflow named "my-job" as defined in the
      # bundle that was just deployed.
      - run: databricks bundle destroy --auto-approve
        working-directory: .
        env:
          DATABRICKS_TOKEN: ${{ secrets.SP_TOKEN }}
          DATABRICKS_BUNDLE_ENV: dev

